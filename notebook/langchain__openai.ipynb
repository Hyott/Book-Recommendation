{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 책소개 / 핵심문장 을 이용한 '생성문장', '해시태그' 생성 프롬프트 및 랭체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"API_KEY: {API_KEY}\")  # 여기에 None이 출력되면 .env 파일이 잘못되었거나 경로 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "import json\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# to generate sentence\n",
    "sentence_system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "당신은 어떤 에세이를 쓴 작가입니다.                                                                     \n",
    "특유의 개성있는 문체를 갖고 있고, 전달하고싶은 메시지가 있으며, 그것을 함축적으로 전달합니다.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "\"\"\")\n",
    "sentence_user_template = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "아래 [text_description]는 제 3자의 시선으로 이 책에 대해 알려주는 글 입니다. 대략적인 내용만 이해하세요.\n",
    "{text_description}\n",
    "\n",
    "아래 [text_key_sentences]는 이 책의 본문에서 추출한 핵심문장들입니다. 작가가 직접 쓴 문장이므로 문체가 담겨있습니다. 문체를 학습하세요.\n",
    "{text_key_sentences}\n",
    "\n",
    "이것은 내용을 요약하라는 요구가 아닙니다.\n",
    "당신은 위 내용의 학습을 통해 이 책의 작가가 됩니다.\n",
    "평이한 문장이 아닌, 잔잔한 울림을 줌과 동시에 독자를 사유하게 만들어야 합니다.\n",
    "28자 이상, 36자 이내의 글로 독자에게 한 마디를 건네세요.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "sentence_prompt_template = ChatPromptTemplate.from_messages([sentence_system_template, sentence_user_template])\n",
    "\n",
    "\n",
    "\n",
    "# to generate hashtag\n",
    "hashtag_system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "당신은 어떤 에세이를 쓴 작가입니다. \n",
    "특유의 개성있는 문체를 갖고 있고, 전달하고싶은 메시지가 있으며, 그것을 함축적으로 전달합니다.                                                                 \n",
    "\"\"\")\n",
    "\n",
    "hashtag_user_template = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "아래 [text_description]는 제 3자의 시선으로 이 책에 대해 알려주는 글 입니다. 대략적인 내용만 이해하세요.\n",
    "{text_description}\n",
    "\n",
    "아래 [text_key_sentences]는 이 책의 본문에서 추출한 핵심문장들입니다. 작가가 직접 쓴 문장이므로 문체가 담겨있습니다.\n",
    "{text_key_sentences}\n",
    "\n",
    "이것은 내용을 요약하라는 요구가 아닙니다.\n",
    "당신은 위 내용의 학습을 통해 이 책의 작가가 됩니다.\n",
    "잔잔한 울림을 줌과 동시에 독자를 사유하게 만들어야 합니다.\n",
    "\n",
    "문체와 작가의 메시지를 가장 도드라지게 표현할 수 있는 해시태그를 정확히 10개를 생성하세요.\n",
    "\n",
    "위 내용을 바탕으로 관련된 해시태그 딱 10개만 작성하세요. \n",
    "- 해시태그 앞에는 반드시 `#`을 붙이고, 공백 없이 작성하세요.\n",
    "- 언더바( _ ) 사용이 불가피하다면 차라리 띄어쓰기 없이 작성하세요.\n",
    "- **출력 시 `_`(언더바)가 포함된 해시태그가 나오면 실패한 결과로 간주합니다.**                                                                                                                                                                                                                                                  \n",
    "\"\"\")\n",
    "\n",
    "hashtag_prompt_template = ChatPromptTemplate.from_messages([hashtag_system_template, hashtag_user_template])\n",
    "\n",
    "\n",
    "\n",
    "# to generate letter\n",
    "letter_system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "당신은 어떤 에세이를 쓴 작가입니다. \n",
    "특유의 개성있는 문체를 갖고 있고, 전달하고싶은 메시지가 있으며, 그것을 편지 형식으로 전달합니다.  \n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "letter_user_template = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "아래 [text_description]는 제 3자의 시선으로 이 책에 대해 알려주는 글 입니다. 대략적인 내용만 이해하세요.\n",
    "{text_description}\n",
    "\n",
    "아래 [text_key_sentences]는 이 책의 본문에서 추출한 핵심문장들입니다. 작가가 직접 쓴 문장이므로 문체가 담겨있습니다.\n",
    "{text_key_sentences}\n",
    "\n",
    "당신은 작가이고, 당신의 책을 기대하는 독자에게 180자 내외의 편지를 쓸거에요.\n",
    "우리끼리 인사는 생략 하기로 해요. 자기가 누구인지 표현하지 마세요. 바로 내용으로 표현해주세요.\n",
    "\n",
    "'사랑하는 독자여, 혹은 친애하는 독자에게 '같은 옛날 책에서 나올법한 좋지 않은 인사말은 절대 하지 말아.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "letter_prompt_template = ChatPromptTemplate.from_messages([letter_system_template, letter_user_template])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Initialize the LLM (using OpenAI GPT as an example)\n",
    "# llm = ChatUpstage(api_key=API_KEY, model_name=\"solar-pro\", temperature=0.7)\n",
    "\n",
    "# OpenAI LLM 설정\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    model_name=\"gpt-4o-mini\",  # GPT-4o Mini 추천 (gpt-3.5-turbo보다 저렴하고 성능 우수)\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 3. Create the LangChain using the template and LLM\n",
    "sentence_chain = LLMChain(llm=llm, prompt=sentence_prompt_template)\n",
    "hashtag_chain = LLMChain(llm=llm, prompt=hashtag_prompt_template)\n",
    "letter_chain = LLMChain(llm=llm, prompt=letter_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Function to process the text and get the result\n",
    "def get_author_message(text_description, text_key_sentences):\n",
    "    time.sleep(1)\n",
    "    return sentence_chain.run({\n",
    "            \"text_description\": text_description,\n",
    "            \"text_key_sentences\": text_key_sentences\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_hashtags(text_description, text_key_sentences):\n",
    "    time.sleep(1)\n",
    "    return hashtag_chain.run({\n",
    "            \"text_description\": text_description,\n",
    "            \"text_key_sentences\": text_key_sentences\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_letter(text_description, text_key_sentences):\n",
    "    time.sleep(1)\n",
    "    return letter_chain.run({\n",
    "            \"text_description\": text_description,\n",
    "            \"text_key_sentences\": text_key_sentences\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 5. Function to process multiple books\n",
    "def process_multiple_books(text_description, text_key_sentences, isbn_list):\n",
    "    results = {}\n",
    "    for idx, (text_ds, text_ks) in enumerate(zip(text_description, text_key_sentences)):\n",
    "        print(f\"Processing book {idx}...\")\n",
    "        message = get_author_message(text_ds, text_ks)\n",
    "        hashtags = get_hashtags(text_ds, text_ks)\n",
    "        letter = get_letter(text_ds, text_ks)\n",
    "        results[f\"Book {idx}\"] = {\n",
    "            \"message\": message,\n",
    "            \"hashtags\": hashtags,\n",
    "            \"letter\": letter,\n",
    "            \"isbn\": isbn_list[idx]\n",
    "        }\n",
    "\n",
    "        # 파일 저장 경로 설정\n",
    "        file_path = \"notebook/data\"\n",
    "        os.makedirs(file_path, exist_ok=True)  # 디렉토리가 없으면 생성\n",
    "\n",
    "        # JSON 파일로 저장\n",
    "        output_file = os.path.join(file_path, \"llm_output.json\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"Results have been saved to {output_file}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 책 데이터로 부터 리스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# JSON 데이터 로드\n",
    "with open('../data/scraping/filtered_book_unique.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(len(data))\n",
    "# description과 key_sentences를 통합한 리스트 생성\n",
    "description_list = []\n",
    "key_sentences_list = []\n",
    "isbn_list = []\n",
    "isbn_loss_idx = []\n",
    "\n",
    "for idx, el in enumerate(data):\n",
    "    # description과 key_sentences를 가져옴\n",
    "    description = el.get('description', '')  # description이 없으면 빈 문자열\n",
    "    key_sentences = el.get('key_sentences',)  # key_sentences가 없으면 빈 문자열\n",
    "    isbn_str = str(el.get('isbn', ''))  # isbn13을 문자열로 변환\n",
    "\n",
    "    # 숫자만 추출하고 빈 문자열인 경우 처리\n",
    "    isbn_numeric = re.sub(r\"\\D\", \"\", isbn_str)\n",
    "    if isbn_numeric:  # 숫자가 있는 경우에만 int 변환\n",
    "        isbn13 = int(isbn_numeric)\n",
    "    else:\n",
    "        isbn13 = None\n",
    "        isbn_loss_idx.append(idx)\n",
    "\n",
    "\n",
    "    # 리스트에 추가\n",
    "    description_list.append(description)\n",
    "    key_sentences_list.append(key_sentences)\n",
    "    isbn_list.append(isbn13)\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"총 {len(key_sentences_list)}개의 항목이 생성되었습니다.\")\n",
    "print(description_list[:1])\n",
    "print(key_sentences_list[:1])  # 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))\n",
    "print(len(description_list))\n",
    "print(len(key_sentences_list))\n",
    "print(len(isbn_list))\n",
    "print(isbn_list[0])\n",
    "print(len(isbn_loss_idx))\n",
    "# print(data[4884])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예외처리 및 실행\n",
    "\n",
    "- 1시간당 750개 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if len(description_list) != len(data) or len(key_sentences_list) != len(data):\n",
    "        print(\"Warning: The length of text_description and text_key_sentences is not the same.\")\n",
    "        min_length = min(len(description_list), len(key_sentences_list))\n",
    "        print(f\"Processing only the first {min_length} items.\")\n",
    "    else:\n",
    "        min_length = len(description_list)\n",
    "\n",
    "\n",
    "    try:\n",
    "        text_description = description_list[:min_length]\n",
    "        text_key_sentences = key_sentences_list[:min_length]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the books: {e}\")\n",
    "\n",
    "    results = process_multiple_books(text_description, text_key_sentences, isbn_list)\n",
    "\n",
    "    output_filename = \"llm_output_last.json\"  # 저장할 파일 이름\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"✅ JSON 파일 저장 완료: {output_filename}\")\n",
    "\n",
    "    \n",
    "    for book, data in results.items():\n",
    "        print(f\"{book} 메시지: {data['message']}\")\n",
    "        print(f\"{book} 해시태그: {data['hashtags']}\")\n",
    "        print(f\"{book} 작가의편지: {data['letter']}\",'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_recommend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
