{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 책소개 / 핵심문장 을 이용한 '생성문장', '해시태그' 생성 프롬프트 및 랭체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"API_KEY: {API_KEY}\")  # 여기에 None이 출력되면 .env 파일이 잘못되었거나 경로 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "import json\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# to generate sentence\n",
    "sentence_system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "당신은 어떤 에세이를 쓴 작가입니다.                                                                     \n",
    "특유의 개성있는 문체를 갖고 있고, 전달하고싶은 메시지가 있으며, 그것을 함축적으로 전달합니다.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "\"\"\")\n",
    "sentence_user_template = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "아래 [text_description]는 제 3자의 시선으로 이 책에 대해 알려주는 글 입니다. 대략적인 내용만 이해하세요.\n",
    "{text_description}\n",
    "\n",
    "아래 [text_key_sentences]는 이 책의 본문에서 추출한 핵심문장들입니다. 작가가 직접 쓴 문장이므로 문체가 담겨있습니다. 문체를 학습하세요.\n",
    "{text_key_sentences}\n",
    "\n",
    "이것은 내용을 요약하라는 요구가 아닙니다.\n",
    "당신은 위 내용의 학습을 통해 이 책의 작가가 됩니다.\n",
    "평이한 문장이 아닌, 잔잔한 울림을 줌과 동시에 독자를 사유하게 만들어야 합니다.\n",
    "28자 이상, 36자 이내의 글로 독자에게 한 마디를 건네세요.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "sentence_prompt_template = ChatPromptTemplate.from_messages([sentence_system_template, sentence_user_template])\n",
    "\n",
    "\n",
    "\n",
    "# to generate hashtag\n",
    "hashtag_system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "당신은 어떤 에세이를 쓴 작가입니다. \n",
    "특유의 개성있는 문체를 갖고 있고, 전달하고싶은 메시지가 있으며, 그것을 함축적으로 전달합니다.                                                                 \n",
    "\"\"\")\n",
    "\n",
    "hashtag_user_template = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "아래 [text_description]는 제 3자의 시선으로 이 책에 대해 알려주는 글 입니다. 대략적인 내용만 이해하세요.\n",
    "{text_description}\n",
    "\n",
    "아래 [text_key_sentences]는 이 책의 본문에서 추출한 핵심문장들입니다. 작가가 직접 쓴 문장이므로 문체가 담겨있습니다.\n",
    "{text_key_sentences}\n",
    "\n",
    "이것은 내용을 요약하라는 요구가 아닙니다.\n",
    "당신은 위 내용의 학습을 통해 이 책의 작가가 됩니다.\n",
    "잔잔한 울림을 줌과 동시에 독자를 사유하게 만들어야 합니다.\n",
    "\n",
    "문체와 작가의 메시지를 가장 도드라지게 표현할 수 있는 해시태그를 정확히 10개를 생성하세요.\n",
    "\n",
    "위 내용을 바탕으로 관련된 해시태그 딱 10개만 작성하세요. \n",
    "- 해시태그 앞에는 반드시 `#`을 붙이고, 공백 없이 작성하세요.\n",
    "- 언더바( _ ) 사용이 불가피하다면 차라리 띄어쓰기 없이 작성하세요.\n",
    "- **출력 시 `_`(언더바)가 포함된 해시태그가 나오면 실패한 결과로 간주합니다.**                                                                                                                                                                                                                                                  \n",
    "\"\"\")\n",
    "\n",
    "hashtag_prompt_template = ChatPromptTemplate.from_messages([hashtag_system_template, hashtag_user_template])\n",
    "\n",
    "\n",
    "\n",
    "# to generate letter\n",
    "letter_system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "당신은 어떤 에세이를 쓴 작가입니다. \n",
    "특유의 개성있는 문체를 갖고 있고, 전달하고싶은 메시지가 있으며, 그것을 편지 형식으로 전달합니다.  \n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "letter_user_template = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "아래 [text_description]는 제 3자의 시선으로 이 책에 대해 알려주는 글 입니다. 대략적인 내용만 이해하세요.\n",
    "{text_description}\n",
    "\n",
    "아래 [text_key_sentences]는 이 책의 본문에서 추출한 핵심문장들입니다. 작가가 직접 쓴 문장이므로 문체가 담겨있습니다.\n",
    "{text_key_sentences}\n",
    "\n",
    "당신은 작가이고, 당신의 책을 기대하는 독자에게 180자 내외의 편지를 쓸거에요.\n",
    "우리끼리 인사는 생략 하기로 해요. 자기가 누구인지 표현하지 마세요. 바로 내용으로 표현해주세요.\n",
    "\n",
    "'사랑하는 독자여, 혹은 친애하는 독자에게 '같은 옛날 책에서 나올법한 좋지 않은 인사말은 절대 하지 말아.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "letter_prompt_template = ChatPromptTemplate.from_messages([letter_system_template, letter_user_template])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Initialize the LLM (using OpenAI GPT as an example)\n",
    "# llm = ChatUpstage(api_key=API_KEY, model_name=\"solar-pro\", temperature=0.7)\n",
    "\n",
    "# OpenAI LLM 설정\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    model_name=\"gpt-4o-mini\",  # GPT-4o Mini 추천 (gpt-3.5-turbo보다 저렴하고 성능 우수)\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 3. Create the LangChain using the template and LLM\n",
    "sentence_chain = LLMChain(llm=llm, prompt=sentence_prompt_template)\n",
    "hashtag_chain = LLMChain(llm=llm, prompt=hashtag_prompt_template)\n",
    "letter_chain = LLMChain(llm=llm, prompt=letter_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Function to process the text and get the result\n",
    "def get_author_message(text_description, text_key_sentences):\n",
    "    time.sleep(1)\n",
    "    return sentence_chain.run({\n",
    "            \"text_description\": text_description,\n",
    "            \"text_key_sentences\": text_key_sentences\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_hashtags(text_description, text_key_sentences):\n",
    "    time.sleep(1)\n",
    "    return hashtag_chain.run({\n",
    "            \"text_description\": text_description,\n",
    "            \"text_key_sentences\": text_key_sentences\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_letter(text_description, text_key_sentences):\n",
    "    time.sleep(1)\n",
    "    return letter_chain.run({\n",
    "            \"text_description\": text_description,\n",
    "            \"text_key_sentences\": text_key_sentences\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 5. Function to process multiple books\n",
    "def process_multiple_books(text_description, text_key_sentences, isbn_list):\n",
    "    results = {}\n",
    "    for idx, (text_ds, text_ks) in enumerate(zip(text_description, text_key_sentences)):\n",
    "        print(f\"Processing book {idx}...\")\n",
    "        message = get_author_message(text_ds, text_ks)\n",
    "        hashtags = get_hashtags(text_ds, text_ks)\n",
    "        letter = get_letter(text_ds, text_ks)\n",
    "        results[f\"Book {idx}\"] = {\n",
    "            \"message\": message,\n",
    "            \"hashtags\": hashtags,\n",
    "            \"letter\": letter,\n",
    "            \"isbn\": isbn_list[idx]\n",
    "        }\n",
    "\n",
    "        # 파일 저장 경로 설정\n",
    "        file_path = \"notebook/data\"\n",
    "        os.makedirs(file_path, exist_ok=True)  # 디렉토리가 없으면 생성\n",
    "\n",
    "        # JSON 파일로 저장\n",
    "        output_file = os.path.join(file_path, \"llm_output.json\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"Results have been saved to {output_file}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 책 데이터로 부터 리스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781\n",
      "총 1749개의 항목이 생성되었습니다.\n",
      "[\"“말과 글에는 나름의 온도가 있다”말과 글에는 나름의 온도가 있다. 따뜻함과 차가움의 정도가 저마다 다르다. 적당히 온기 있는 언어는 슬픔을 감싸 안아준다. 세상살이에 지칠 때 어떤 이는 친구와 이야기를 주고받으며 고민을 털어내고, 어떤 이는 책을 읽으며 작가가 건네는 문장에서 위안을 얻는다. 그렇다면 이 책을 집어 든 우리의 언어 온도는 몇 도쯤 될까? 무심결에 내뱉은 말 한마디 때문에 소중한 사람이 곁을 떠났다면 '말 온도'가 너무 뜨거웠던 게 아닐까. 한두 줄 문장 때문에 누군가 마음의 문을 닫았다면 '글 온도'가 너무 차갑기 때문인지도 모를 노릇이다. 어쩌면.작가 이기주는 엿듣고 기록하는 일을 즐겨 하는 사람이다. 그는 버스나 지하철에 몸을 실으면 몹쓸 버릇이 발동한다고 고백한다. 귀를 쫑긋 세운 채 평범한 사람들의 대화에 귀를 기울인다. 그리고 꽤 의미 있는 문장이 귀로 스며들면 그것을 슬그머니 메모한다. 그들이 무심코 교환하는 말과 끄적이는 문장에 절절한 사연이 도사리고 있을 것 같기 때문이다. 『언어의 온도』는 저자가 일상에서 발견한 의미 있는 말과 글, 단어의 어원과 유래, 그런 언어가 지닌 소중함과 절실함을 농밀하게 담아낸 책이다. 페이지를 넘길 때마다 문장과 문장에 호흡을 불어넣으며 적당히 뜨거운 음식을 먹듯 찬찬히 곱씹어 읽다 보면, 각자의 ‘언어 온도’를 되짚어볼 수 있을지 모른다.\"]\n",
      "['언어의 온도어제 노트북을 켜고 ‘사람’을 입력하려다 실수로 ‘삶’을 쳤다. 그러고 보니 ‘사람’에서 슬며시 받침을 바꾸면 ‘사랑’이 되고 ‘사람’에서 은밀하게 모음을 빼면 ‘삶’이 된다. 세 단어가 닮아서일까. 사랑에 얽매이지 않고 살아가는 사람도, 사랑이 끼어들지 않는 삶도 없는 듯하다.---「사랑이란 말은 어디에서 왔을까」중에서안주가 떨어질 무렵, 사랑에 관한 이야기로 주제가 옮겨갔다. 잡지사에서 에디터로 일하는 친구는 사랑에 빠지는 순간 불온한 상상을 하게 된다고 힘주어 말했다. “누군가를 좋아하면 상대의 ‘낮’은 물론이고 상대의 ‘밤’도 갖은 싶은 욕망에 사로잡히는 법이지. 때론 서로의 감정을 믿고 서로의 밤을 훔치는 확신범이 되려 하지. 암, 그게 사랑일 테지.”철학 서적을 주로 기획하고 출간하는 출판사 사장은 이런 이야기를 보탰다. “흔히 말하는 ‘썸’이란 것은, 좋아하는 감정이 있다는 ‘확신’과 ‘의심’ 사이의 투쟁이야. 확신과 의심이 밀물과 썰물처럼 교차하는 법이지. 그러다 의심의 농도가 점차 옅어져 확신만 남으면 비로소 사랑이 시작되는 게 아닐까?”---「여전히 당신을 염려하오’ 중에서글은 여백 위에만 남겨지는 게 아니다. 머리와 가슴에도 새겨진다. 마음 깊숙이 꽂힌 글귀는 지지 않는 꽃이다. 우린 그 꽃을 바라보며 위안을 얻는다. 때론 단출한 문장 한 줄이 상처를 보듬고 삶의 허기를 달래기도 한다.---「긁다, 글, 그리움」중에서이누이트(에스키모)들은 분노를 현명하게 다스린다. 아니, 놓아준다. 그들은 화가 치밀어 오르면 하던 일을 멈추고 무작정 걷는다고 한다. 언제까지? 분노의 감정이 스르륵 가라앉을 때까지.그리고 충분히 멀리 왔다 싶으면 그 자리에 긴 막대기 하나를 꽂아두고 온다. 미움, 원망, 서러움으로 얽히고설킨, 누군가에게 화상을 입힐지도 모르는 지나치게 뜨거운 감정을 그곳에 남겨두고 돌아오는 것이다.---「분노를 대하는 방법」중에서한 번은 여행과 방황의 유사성에 대해 생각한 적도 있다. 둘 다 ‘떠나는 일’이란 점에서는 닮았다. 그러나 두 행위의 시작만 비슷할 뿐 마지막은 큰 차이가 있다.여행을 의미하는 영어 단어 ‘tour’는 ‘순회하다’ ‘돌다’라는 뜻의 라틴어 ‘tornus’에서 유래했다. 흐르는 것은 흘러 흘러 제자리로 돌아오는 속성을 지닌다. 여행길에 오른 사람은 언젠가는 여행의 출발지로 되돌아온다. 돌아갈 곳이 없다면 그건 여행이 아니라 방황인지도 모른다.---「여행의 목적」중에서사랑하는 사람과 시선을 나눌 수 있다는 것, 참으로 소중한 일이 아닐 수 없다. 눈을 동그랗게 뜨고 상대를 자세히 응시하는 행위는 우리 삶에서 꽤 중요한 의미를 지닌다. 그래서 ‘관찰 = 관심’이라는 등식이 성립하기도 한다.사람은 관심이 부족하면 상대를 쳐다보지 않는다. 궁금할 이유가 없으므로 시선을 돌리게 된다. 외면하는 것이다. “당신이 보고 싶지 않아요”라는 말은, “그쪽에 관심이 없어요” 혹은 “뜨겁던 마음이 어느 순간 시들해졌어요. 아니 차가워졌어요”라는 말과 동일하게 쓰이곤 한다.그래서일까. 돌이켜보면 관심이 멈추던 순간, 상대를 향한 관찰도 멈췄던 것 같다.\\n---「관찰은 곧 관심」중에서']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# JSON 데이터 로드\n",
    "with open('../data/scraping/filtered_book_unique.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(len(data))\n",
    "# description과 key_sentences를 통합한 리스트 생성\n",
    "description_list = []\n",
    "key_sentences_list = []\n",
    "isbn_list = []\n",
    "isbn_loss_idx = []\n",
    "\n",
    "for idx, el in enumerate(data):\n",
    "    # description과 key_sentences를 가져옴\n",
    "    description = el.get('description', '')  # description이 없으면 빈 문자열\n",
    "    key_sentences = el.get('key_sentences',)  # key_sentences가 없으면 빈 문자열\n",
    "    isbn_str = str(el.get('isbn', ''))  # isbn13을 문자열로 변환\n",
    "\n",
    "    # 숫자만 추출하고 빈 문자열인 경우 처리\n",
    "    isbn_numeric = re.sub(r\"\\D\", \"\", isbn_str)\n",
    "    if isbn_numeric:  # 숫자가 있는 경우에만 int 변환\n",
    "        isbn13 = int(isbn_numeric)\n",
    "    else:\n",
    "        isbn13 = None\n",
    "        isbn_loss_idx.append(idx)\n",
    "\n",
    "\n",
    "    # 리스트에 추가\n",
    "    description_list.append(description)\n",
    "    key_sentences_list.append(key_sentences)\n",
    "    isbn_list.append(isbn13)\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"총 {len(key_sentences_list)}개의 항목이 생성되었습니다.\")\n",
    "print(description_list[:1])\n",
    "print(key_sentences_list[:1])  # 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781\n",
      "1749\n",
      "1749\n",
      "1749\n",
      "9791195522125\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(description_list))\n",
    "print(len(key_sentences_list))\n",
    "print(len(isbn_list))\n",
    "print(isbn_list[0])\n",
    "print(len(isbn_loss_idx))\n",
    "# print(data[4884])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예외처리 및 실행\n",
    "\n",
    "- 1시간당 750개 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if len(description_list) != len(data) or len(key_sentences_list) != len(data):\n",
    "        print(\"Warning: The length of text_description and text_key_sentences is not the same.\")\n",
    "        min_length = min(len(description_list), len(key_sentences_list))\n",
    "        print(f\"Processing only the first {min_length} items.\")\n",
    "    else:\n",
    "        min_length = len(description_list)\n",
    "\n",
    "\n",
    "    try:\n",
    "        text_description = description_list[:min_length]\n",
    "        text_key_sentences = key_sentences_list[:min_length]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the books: {e}\")\n",
    "\n",
    "    results = process_multiple_books(text_description, text_key_sentences, isbn_list)\n",
    "\n",
    "    output_filename = \"llm_output_last.json\"  # 저장할 파일 이름\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"✅ JSON 파일 저장 완료: {output_filename}\")\n",
    "\n",
    "    \n",
    "    for book, data in results.items():\n",
    "        print(f\"{book} 메시지: {data['message']}\")\n",
    "        print(f\"{book} 해시태그: {data['hashtags']}\")\n",
    "        print(f\"{book} 작가의편지: {data['letter']}\",'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_recommend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
