{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 책소개 / 핵심문장 을 이용한 '생성문장', '해시태그' 생성 프롬프트 및 랭체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pv/stmwcx8d7dsf_j4ytc5gp5780000gn/T/ipykernel_3678/1694209679.py:113: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  sentence_chain = LLMChain(llm=llm, prompt=sentence_prompt_template)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import json\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "# to generate sentence\n",
    "sentence_system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "당신은 작가의 문체를 학습하고 독자에게 전달하고자 하는 메시지를 생성하는 전문가입니다.\n",
    "주어진 책의 소개글과 핵심 문장을 기반으로 **작가의 문체를 반영한 짧은 메시지를 작성**하세요.                                                                  \n",
    "\n",
    "작성 조건 : \n",
    "- 30자 이내로 작성하세요.\n",
    "- 작가의 이름을 포함하지 마세요.\n",
    "- 난해한 표현을 피하세요.\n",
    "- **문어체를 사용하세요.**                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "\"\"\")\n",
    "sentence_user_template = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "아래 [text_description]는 이 책의 소개글 입니다. 제 3자의 시선으로 이 책에 대해 알려주는 글 입니다.\n",
    "{text_description}\n",
    "\n",
    "아래 [text_key_sentences]는 이 책의 본문에서 추출한 핵심문장들입니다. 작가가 직접 쓴 문장이므로 문체가 담겨있습니다. 문체를 학습하세요.\n",
    "{text_key_sentences}\n",
    "\n",
    "위의 내용을 기반으로, 독자에게 작가가 전달하고 싶은 메시지를 작성해주세요.  \n",
    "단, 이 작가의 문체를 반영해야 합니다.\n",
    "**책의 핵심 내용을 요약하여 담고 있어야 합니다.**\n",
    "\"\"\")\n",
    "sentence_prompt_template = ChatPromptTemplate.from_messages([sentence_system_template, sentence_user_template])\n",
    "\n",
    "\n",
    "\n",
    "# to generate hashtag\n",
    "hashtag_system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "당신은 책에 대한 정보를 바탕으로 적절한 해시태그를 생성하는 전문가입니다.\n",
    "책의 소개글과 핵심 문장들을 분석하여 관련된 해시태그만 10개 작성하세요.\n",
    "해시태그의 설명은 필요없습니다.                                                                   \n",
    "\"\"\")\n",
    "\n",
    "hashtag_user_template = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "아래 [text_description]는 이 책의 소개글 입니다. 제 3자의 시선으로 이 책에 대해 알려주는 글 입니다.\n",
    "{text_description}\n",
    "\n",
    "아래 [text_key_sentences]는 이 책의 본문에서 추출한 핵심문장들입니다. 작가가 직접 쓴 문장이므로 문체가 담겨있습니다.\n",
    "{text_key_sentences}\n",
    "\n",
    "위 내용을 바탕으로 관련된 해시태그 딱 10개만 작성하세요.\n",
    "- 책의 핵심 주제와 감성을 반영해야 합니다.\n",
    "- 일반적인 태그 (#독서, #책추천)나 작가이름(#한강에세이), 카테고리(#힐링)보다 책의 개성을 보여주는 태그를 포함하세요.   \n",
    "- 감성적 태그 (#마음에_와닿는_책), 장르 태그 (#심리치유), 실용적 태그 (#자기계발서) 등을 혼합하세요. \n",
    "- 해시태그 앞에는 반드시 `#`을 붙이고, 공백 없이 작성하세요.\n",
    "- **절대 `_`(언더바)를 사용하지 마세요.** (예: `#책_추천` → `#책추천`으로 수정)\n",
    "- **출력 시 `_`(언더바)가 포함된 해시태그가 나오면 실패한 결과로 간주합니다.**  \n",
    "                                                                                                                                                                                             \n",
    "**❌ 피해야 할 예시**                                                                 \n",
    "- #일의_감각 (잘못된 형식, `_` 포함)\n",
    "- #브랜드_스토리 (잘못된 형식, `_` 포함)                                                                \n",
    "\n",
    "**✅ 올바른 예시**\n",
    "- #일의감각 (공백 없이 작성)\n",
    "- #브랜드스토리 (공백 없이 작성)                                                                                                                                                                                                                                                 \n",
    "\"\"\")\n",
    "\n",
    "hashtag_prompt_template = ChatPromptTemplate.from_messages([hashtag_system_template, hashtag_user_template])\n",
    "\n",
    "\n",
    "\n",
    "# to generate letter\n",
    "letter_system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "당신은 이 책의 작가입니다. 이 책을 찾은 독자들에게 책을 추천하는 편지를 씁니다.\n",
    "\n",
    "편지 작성 기준 :\n",
    "- **반드시 200자이내**로 작성하세요.(300자를 초과하면 실패한 결과로 간주합니다.)\n",
    "- 마치 독자와 직접 대화하는 듯한 편지 형식으로 작성하세요.\n",
    "- 독자가 이 책을 읽고 싶어지도록 **기대감을 주는 내용**이어야 합니다.\n",
    "- **작가의 인사나, 소개는 꼭 작성하지 않습니다.**                                                                                                                                                                                                                                                                                                                                            \n",
    "\"\"\")\n",
    "\n",
    "letter_user_template = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "아래 [text_description]는 이 책의 소개글 입니다. 제 3자의 시선으로 이 책에 대해 알려주는 글 입니다.\n",
    "{text_description}\n",
    "\n",
    "아래 [text_key_sentences]는 이 책의 본문에서 추출한 핵심문장들입니다. 작가가 직접 쓴 문장이므로 문체가 담겨있습니다.\n",
    "{text_key_sentences}\n",
    "\n",
    "위 내용과 문체를 학습한 후, 이 책의 작가로서 독자에게 강렬한 편지를 남겨주세요.\n",
    "- 책을 읽기 전 독자가 책을 기대할 수 있게 감정을 전달하세요.\n",
    "- 책의 **분위기와 작가 특유의 문체를 자연스럽게 반영**하세요.\n",
    "- **꼭 독자에게 직접 말하는 듯한 어조를 사용하세요.**\n",
    "- **반드시 200자이내**로 작성하세요.(300자를 초과하면 실패한 결과로 간주합니다.)\n",
    "- **작가의 인사나, 소개는 꼭 작성하지 않습니다.** \n",
    "                                                                \n",
    "**❌ 피해야 할 예시** \n",
    "- 안녕하세요, 독자님.\n",
    "- 안녕하세요, 독자에게.\n",
    "- 안녕하세요                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "\"\"\")\n",
    "\n",
    "letter_prompt_template = ChatPromptTemplate.from_messages([letter_system_template, letter_user_template])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Initialize the LLM (using OpenAI GPT as an example)\n",
    "llm = ChatUpstage(api_key=API_KEY, model_name=\"solar-pro\", temperature=0.7)\n",
    "\n",
    "# 3. Create the LangChain using the template and LLM\n",
    "sentence_chain = LLMChain(llm=llm, prompt=sentence_prompt_template)\n",
    "hashtag_chain = LLMChain(llm=llm, prompt=hashtag_prompt_template)\n",
    "letter_chain = LLMChain(llm=llm, prompt=letter_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Function to process the text and get the result\n",
    "def get_author_message(text_description, text_key_sentences):\n",
    "    time.sleep(1)\n",
    "    return sentence_chain.run({\n",
    "            \"text_description\": text_description,\n",
    "            \"text_key_sentences\": text_key_sentences\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_hashtags(text_description, text_key_sentences):\n",
    "    time.sleep(1)\n",
    "    return hashtag_chain.run({\n",
    "            \"text_description\": text_description,\n",
    "            \"text_key_sentences\": text_key_sentences\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_letter(text_description, text_key_sentences):\n",
    "    time.sleep(1)\n",
    "    return letter_chain.run({\n",
    "            \"text_description\": text_description,\n",
    "            \"text_key_sentences\": text_key_sentences\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 5. Function to process multiple books\n",
    "def process_multiple_books(text_description, text_key_sentences, isbn_list):\n",
    "    results = {}\n",
    "    for idx, (text_ds, text_ks) in enumerate(zip(text_description, text_key_sentences)):\n",
    "        print(f\"Processing book {idx}...\")\n",
    "        message = get_author_message(text_ds, text_ks)\n",
    "        hashtags = get_hashtags(text_ds, text_ks)\n",
    "        letter = get_letter(text_ds, text_ks)\n",
    "        results[f\"Book {idx}\"] = {\n",
    "            \"message\": message,\n",
    "            \"hashtags\": hashtags,\n",
    "            \"letter\": letter,\n",
    "            \"isbn\": isbn_list[idx]\n",
    "        }\n",
    "\n",
    "        # 파일 저장 경로 설정\n",
    "        file_path = \"notebook/data\"\n",
    "        os.makedirs(file_path, exist_ok=True)  # 디렉토리가 없으면 생성\n",
    "\n",
    "        # JSON 파일로 저장\n",
    "        output_file = os.path.join(file_path, \"llm_output.json\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"Results have been saved to {output_file}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 책 데이터로 부터 리스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781\n",
      "총 5개의 항목이 생성되었습니다.\n",
      "['★ 누적 조회수 9억 뷰, 100만 크리에이터 ‘얼미부부’ 첫 에세이 ★★ SNS 웃음 폭탄 얼미부부만의 행복 소환 노하우 대방출 ★“우리 자기들 더 행복해질 준비해요 아주 그냥!”잇몸 마르게 웃다가도 갑자기 마음이 찡해지고느닷없이 행복을 깨닫게 된다헌팅 포차에서 개그 배틀을 하다 서로에게 반하고 11년 사귄 후 결혼한 커플. 유쾌한 티키타카와 쉴 새 없이 서로를 웃게 만드는 일상을 담은 영상들로 단숨에 100만 크리에이터가 되었다. 얼미부부의 틱톡과 유튜브, 릴스에는 “얼미부부 영상을 보면 행복해져요!”, “결혼하면 얼미부부처럼 살고 싶어요”, “일반인 구독해서 보는 건 처음이에요. 너무 웃겨요” 같은 댓글이 폭주한다. 그들만의 행복 에너지는 3년 만에 누적 조회수 9억 뷰를 만들었다.구독자들에게 웃음을 전하는 얼미부부에게도 힘든 날은 있었다. 개그맨 공채 다섯 번 탈락, 대학 입시 포기, 20만 원 반지하 월셋방과 가수 오디션 고배까지……. 우울한 나날이 속절없이 밀려왔지만 인생의 고난이 둘의 행복을 가로막지는 못했다. 실패하고 넘어져도 다시 시도하고, 때로는 깨끗하게 포기하는 용기를 내야 할 때 든든하게 믿고 지켜봐준 서로가 있었기 때문이다. 무엇보다 평범한 일상에서도 서로의 웃음 버튼을 눌러주는 노력을 게을리 한 적이 없다. 얼미부부는 서로 오래 사랑하고 행복을 놓치지 않는 비밀을 “혼자 행복한 사람이 같이 있을 때도 행복하다”라는 마음가짐에서 찾는다.자기들 행복만큼이나 구독자들의 행복에도 진심인 이들은 용기 내어 자신들의 이야기를 전하기로 했다. 얼미부부표 행복 소환 에세이 『우리는 날마다 조금씩 행복해진다』는 행복은 그리 멀지 않다는 것, 행복도 습관처럼 언제든 연습할 수 있다는 메시지를 진심을 담아 전하고 있다. 대한민국 최애 부부로 등극한 얼미부부와 함께 1일 1행복을 소환하는 주문을 외쳐보자. “엉망진창 같아도 결국엔 해피엔딩이야!”']\n",
      "['그래서 우리는 불행을 건너뛰기로 했다. 우리는 우울한 날에도 하루 한 번씩 꼭 웃었다. 나름 예술계 입문을 꿈꾼 덕분인지, 폼을 잡고 싶었던 건지도 모른다. 하지만 우리가 확신하는 건 있었다. 꿈이 나에게서 자꾸만 멀어져간다고 해도 그게 삶의 행복을 무너뜨릴 수는 없다는 것, 좌절이나 실패가 우리의 앞날을 없앨 수 없다는 것이었다. 웃기 힘든 날에는 마음속으로 이 말을 되뇌었다.“어차피 내 인생의 결말은 해피엔딩이니까!”--- p.12만남이라는 건 언제 어디에서 올지 모른다 하더니, 내가 그 이야기의 주인공이 되리라곤 상상도 못 했다. 운명의 상대든 하늘이 내려준 짝이든 아무리 오라고 해도 안 오는 때가 있고, 나 혼자 열심히 살 테니까 아무도 오지 말라고 죽어라 외쳐도 끝내 나에게 당도하는 사람이 있다. 지금도 종종 그런 생각을 한다. 내가 만약 헌팅 포차인 걸 알고 그 자리를 피했다면, 아니면 얼이의 기차 소리에도 콧방귀도 안 뀌었다면 운명은 또 어떤 순간에 우리를 만나게 해줬을까?--- p.27‘인생은 내가 주인공인 영화다. 고난과 극복이 수없이 반복되겠지만 이 영화의 결말은 어차피 해피엔딩이다.’내 인생의 좌우명이다. 이 말처럼 생각하면 지금 눈앞에 닥친 힘든 일이 아주 조금은 나아진다. 곰곰 생각해보자. 해피엔딩인 영화를 보면 주인공들은 항상 크고 작은 고난을 겪고 어려움을 헤쳐 나간다. 그런데 고초와 시련이라는 여정은 결국엔 좋은 결과로 가는 거름이 된다. 나에게 지금 일어난 힘든 일들이 해피엔딩을 위한 과정이라고 생각하면 조금 견딜 만해진다.--- p.44음미가 가장 강조하는 말이 있다.“혼자 있을 때 행복한 사람이 둘이 있을 때도 행복할 수 있어!”맞는 말이다. 혼자 있는 게 외롭고 무언가 부족하다고 느끼면 자꾸만 상대에게 바라게 된다. 마음이든 행동이든. 우리가 장기 연애 커플로 결혼까지 할 수 있었던 이유, 짧은 시간 만나고 군입대로 떨어져 있었지만 믿음이 깨지지 않았던 이유는 특별한 게 아니었다.--- p.61이제는 과거의 불안과 압박이 깔끔하게 사라졌다. 지금 우리 머리 위에 있는 하늘이 굉장히 맑고 푸른데, 스스로 먹구름을 불러와서 맑은 날을 보지 못하는 건 아닐까? 전혀 그럴 필요가 없는데 말이다. 아직은 더 많은 경험이 앞에 놓여 있다는 기대만으로도 충분히 기분 좋은 오늘을 누리고 있다. 우리는 이따금 코앞에 있는 행복을 보지 못한 채 길을 헤매며 애써 나쁜 일을 찾는다. 행복은 멀리 있지 않다. 없는 것을 보이지 않는 곳에서 찾으려 하면 할수록 지금의 행복은 옅어지고 사라질 뿐이다. 오늘을 충실하게 살다 보면 잘될 것이라는 믿음으로 행복을 누리기를 바란다.--- p.73‘나는 어떤 사람이 되고 싶은가’에 대해 생각해본 적이 있다. 떠오른 답은 보기만 해도 웃음이 나고 좋은 에너지가 느껴지는 사람이었다. 내가 나로서 자존감을 지키고 앞으로 나아가는 것도 중요하지만, 긍정적인 에너지가 다른 사람에게 충분히 가닿을 때 더 큰 보람을 느낀다. 그래서 나는 처음 보는 사람에게도 밝게 인사하려고 노력하고, 긍정적인 말을 나 자신에게뿐만 아니라 다른 사람에게도 자주 건넨다.--- p.105나에 대해 알아갈수록 재미있었다. 특히나 이십 대에서 삼십 대로 넘어가면서 내 안에 쌓인 경험이 많아질수록 나를 더 풍부하게 알 수 있었다. 남들 시선에 얽매여 있는 모습이 아닌 진정한 나를 이해하게 된 것이다. 그렇게 나를 알게 되니 인생에 심심할 틈이 없었다. 내가 좋아하는 ‘나’를 데리고 해야 할 일도 많았고, 해주고 싶은 것도 많았다. 그러다 보니 어느 순간 내 마음에 행복이 소소하게 자라고 있었다.--- p.123솔직히 말하면, 무언가에 도전하는 내 모습에 취해 있었다. 결국엔 실패였더라도 시작했다는 사실만으로도 성취감이 온몸에 차올랐다. 이 성취감은 쉽게 중독된다. 새로운 일, 안 해본 일에 도전하는 게 전혀 두렵지 않았다.‘실패하면 뭐 어때. 아무튼 난 최선을 다했는데?’ 이런 자신감이 늘 마음 가득 차 있었다. 그렇게 도전하면서 깨달은 것은 더 있었다. 내가 관심 가진 일이 정말 내 적성에 맞는지를 선별하는 능력이었다. 더 배울 것인지 말 것인지, ‘고!’ 할지 ‘스톱!’ 할지를 능수능란하게 분별하게 됐다.--- p.137인생을 파도 같다고 표현하는데 연애도 마찬가지다. 아무리 사랑하는 사이라 해도 어떻게 늘 좋기만 할까? 조금 잔잔할 때도 있고 거친 파도가 몰아칠 때도 있다. 모든 게 강약강약, 단짠단짠이라는 걸 받아들이면 그 어떤 상황도 자연스럽게 느껴진다.둘의 신뢰가 충분하다면 모든 상황을 자연스럽게 받아들이게 된다. 상대 마음이 변했다는 섭섭한 마음이 들기 전에 ‘아, 오늘은 기분이 별로구나?’, ‘바쁘다더니 그런가 보네’ 하며 넘어갈 수 있다.--- p.164가끔 그런 생각이 든다. 지금의 얼미부부가 되기 위해 그토록 지난한 시간을 보냈던 게 아니었을까? 그리고 열심히 짠 콩트를 방송국에서 선보일 순 없었지만, 콩트를 짜면서 생긴 에피소드들이 지금 구독자에게 재미를 줄 수 있는 소재가 된 게 아닐까?“슬픔은 영원할 수 없다.” 이 말이 피부로 와 닿기까지 많은 시간이 걸렸다. 하지만 이 책을 읽는 누군가에게도 꼭 해주고 싶은 말이다. 도전에 거듭 실패해도 괜찮다. 내가 통과하는 모든 시간과 사건이 언젠가 귀한 기회를 가져다줄 것이다.\\n--- p.184']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# JSON 데이터 로드\n",
    "with open('../data/scraping/filtered_book_unique.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(len(data))\n",
    "# description과 key_sentences를 통합한 리스트 생성\n",
    "description_list = []\n",
    "key_sentences_list = []\n",
    "isbn_list = []\n",
    "isbn_loss_idx = []\n",
    "\n",
    "for idx, el in enumerate(data[100:105]):\n",
    "    # description과 key_sentences를 가져옴\n",
    "    description = el.get('description', '')  # description이 없으면 빈 문자열\n",
    "    key_sentences = el.get('key_sentences',)  # key_sentences가 없으면 빈 문자열\n",
    "    isbn_str = str(el.get('isbn', ''))  # isbn13을 문자열로 변환\n",
    "\n",
    "    # 숫자만 추출하고 빈 문자열인 경우 처리\n",
    "    isbn_numeric = re.sub(r\"\\D\", \"\", isbn_str)\n",
    "    if isbn_numeric:  # 숫자가 있는 경우에만 int 변환\n",
    "        isbn13 = int(isbn_numeric)\n",
    "    else:\n",
    "        isbn13 = None\n",
    "        isbn_loss_idx.append(idx)\n",
    "\n",
    "\n",
    "    # 리스트에 추가\n",
    "    description_list.append(description)\n",
    "    key_sentences_list.append(key_sentences)\n",
    "    isbn_list.append(isbn13)\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"총 {len(key_sentences_list)}개의 항목이 생성되었습니다.\")\n",
    "print(description_list[:1])\n",
    "print(key_sentences_list[:1])  # 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781\n",
      "5\n",
      "5\n",
      "5\n",
      "9788901284521\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(description_list))\n",
    "print(len(key_sentences_list))\n",
    "print(len(isbn_list))\n",
    "print(isbn_list[0])\n",
    "print(len(isbn_loss_idx))\n",
    "# print(data[4884])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예외처리 및 실행\n",
    "\n",
    "- 1시간당 750개 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The length of text_description and text_key_sentences is not the same.\n",
      "Processing only the first 5 items.\n",
      "Processing book 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pv/stmwcx8d7dsf_j4ytc5gp5780000gn/T/ipykernel_3678/515208469.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return sentence_chain.run({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to notebook/data/llm_output.json\n",
      "Processing book 1...\n",
      "Results have been saved to notebook/data/llm_output.json\n",
      "Processing book 2...\n",
      "Results have been saved to notebook/data/llm_output.json\n",
      "Processing book 3...\n",
      "Results have been saved to notebook/data/llm_output.json\n",
      "Processing book 4...\n",
      "Results have been saved to notebook/data/llm_output.json\n",
      "✅ JSON 파일 저장 완료: book_information.json\n",
      "Book 0 메시지: 행복은 습관입니다. 연습하세요.\n",
      "Book 0 해시태그: #행복소환 #일상행복 #행복습관 #행복노하우 #연애꿀팁 #소통법 #실패극복 #도전정신 #자기이해 #에세이추천\n",
      "Book 0 작가의편지: 책장을 넘기는 순간, 당신의 인생이 해피엔딩임을 깨닫게 될 거예요. 우리도 해냈거든요! 함께 웃고, 울며 행복을 찾아나서요. 이 책을 통해 당신의 인생도 조금씩 행복해지길 바랍니다. \n",
      "\n",
      "Book 1 메시지: 좋아지는 일들이 더 많았으면 합니다.\n",
      "Book 1 해시태그: #계절산문 #박준시인 #서정적산문 #사계절의기억 #좋은것들과함께 #좋아지는일들 #은근슬쩍스스로를좋아할수도있을테니까요 #한철동안의아름다운모습 #아름다운우리의가을날 #서로에게번화했으므로시간은우리를웃자라게했습니다\n",
      "Book 1 작가의편지: 살아가면서 좋아지는 일들이 더 많았으면 합니다. 좋은 것들과 함께라면, 은근슬쩍 스스로를 좋아할 수 있을 테니까요. 이 계절, 함께 산책하지 않으시겠습니까? \n",
      "\n",
      "Book 2 메시지: 좋은 대화는 숙성된 진심에서 나옵니다.\n",
      "Book 2 해시태그: #서정적인대화\n",
      "#풍부한표현력\n",
      "#진심을나눈인생\n",
      "#상어식대화\n",
      "#고래식대화\n",
      "#이불킥의기억\n",
      "#입장\n",
      "#숙성의시간\n",
      "#동생의결혼식축사\n",
      "#나만의굴\n",
      "Book 2 작가의편지: 당신의 대화는 밀도가 있습니까? 이 책에는 인생의 골목 곳곳에서 만난 인연과 나눈 진심 어린 대화가 담겨 있습니다. 이 책을 펼치는 순간, 일상의 대화를 되돌아보고 스스로와 밀도 있는 대화를 나누는 시간을 가지게 될 것입니다. 진심을 나눈 인생, 그것이야말로 성공한 인생 아닐까요? \n",
      "\n",
      "Book 3 메시지: 계획은 유연하게, 명언은 자유롭게.\n",
      "Book 3 해시태그: #좋은문장 #명언창고 #삶의단초 #계획표 #파워J #루틴 #정신건강 #에세이 #한국적문화 #화병\n",
      "Book 3 작가의편지: 안녕하세요, 독자님. “잘 모르는 사람이 신념을 가지면 무섭다”는 말, 들어보셨나요? 이 책은 바로 그런 문장들, 마음의 버튼을 누르는 문장들로 가득합니다. 『아무튼, 명언』을 통해 당신만의 ‘명언 창고’를 만들어보세요. 후회하지 않을 거예요. \n",
      "\n",
      "Book 4 메시지: 길처럼 주어진 인생을 사랑하라.\n",
      "Book 4 해시태그: #나태주식사랑법 #인생사색 #사랑이란 #인생의에너지 #자기계발 #꿈찾기 #행복해지는법 #마음속별 #길은인생이다 #고마운사람들\n",
      "Book 4 작가의편지: 안녕하세요, 독자님. 이 책을 읽고 나면, 당신은 비로소 '사랑'을 이해하게 될 거예요. 하지만 그 이해는 실체가 잡히지 않는, 애매모호한 안개 속을 헤매는 것처럼 느껴질지도 모르죠. 그럼에도 불구하고, 당신을 '살아나는 사람'으로 만들어 줄 거예요. 함께 그 길을 걸어봐요. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if len(description_list) != len(data) or len(key_sentences_list) != len(data):\n",
    "        print(\"Warning: The length of text_description and text_key_sentences is not the same.\")\n",
    "        min_length = min(len(description_list), len(key_sentences_list))\n",
    "        print(f\"Processing only the first {min_length} items.\")\n",
    "    else:\n",
    "        min_length = len(description_list)\n",
    "\n",
    "\n",
    "    try:\n",
    "        text_description = description_list[:min_length]\n",
    "        text_key_sentences = key_sentences_list[:min_length]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the books: {e}\")\n",
    "\n",
    "    results = process_multiple_books(text_description, text_key_sentences, isbn_list)\n",
    "\n",
    "    output_filename = \"book_information.json\"  # 저장할 파일 이름\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"✅ JSON 파일 저장 완료: {output_filename}\")\n",
    "\n",
    "    \n",
    "    for book, data in results.items():\n",
    "        print(f\"{book} 메시지: {data['message']}\")\n",
    "        print(f\"{book} 해시태그: {data['hashtags']}\")\n",
    "        print(f\"{book} 작가의편지: {data['letter']}\",'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_recommend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
