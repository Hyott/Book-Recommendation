from fastapi import FastAPI, Depends, HTTPException
from sqlalchemy.orm import Session
from database.connection import get_db
import psycopg2
from database.crud import get_book_by_isbn, get_sentence_by_isbn, add_user_response, get_question_number_by_user_id
from database.schemas import BookSchema, SentenceSchema, UserResponseSchema
from fastapi.middleware.cors import CORSMiddleware
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
from services.book_rec_module import load_embeddings, select_books, \
    update_data, get_message_by_id, weighted_sampling, get_choice_bool, get_sentence_from_db
from dotenv import load_dotenv
import os
from app.database.connection import database_engine
from fastapi.responses import JSONResponse

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
host = os.getenv("HOST")
port = os.getenv("POSTGRES_PORT")
user = os.getenv("POSTGRES_USER")
password = os.getenv("POSTGRES_PASSWORD")
database_name = os.getenv("DATABASE_NAME")

#cursor ì„¤ì •
engine_for_cursor = database_engine(host, port, user, password, database_name)

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì¶œì²˜ í—ˆìš© (ë°°í¬ ì‹œ íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ ì¶”ì²œ)
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš©
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)

# Global variables for the session
presented_books = set()
round_num = 0
alpha = []
beta_values = []
book_data = None
user_id = None
question_number = 0
cluster_to_books = None
initial_prob = 0.3
decay_factor = 0.9
uncertainty_factor = 10
noise_factor = 0.01
embedding_save_path = "notebook/notebook/data/book_embeddings.npz"

num_clusters = 10

@app.get("/books/{isbn}")
def get_book(isbn: str, db: Session = Depends(get_db)):
    if len(isbn) != 13 or not isbn.isdigit():
        raise HTTPException(
            status_code=400,
            detail="Invalid ISBN format. ISBN must be a 13-digit number."
        )
    
    book = get_book_by_isbn(db, isbn)
    if book is None:
        raise HTTPException(
            status_code=404,
            detail=f"Book with ISBN {isbn} not found."
        )
    return book


@app.get("/sentences/{isbn}", response_model=SentenceSchema)
def read_sentence(isbn: str, db: Session = Depends(get_db)):
    sentence = get_sentence_by_isbn(db, isbn)
    if sentence is None:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ISBNì˜ ìƒì„±ë¬¸ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return sentence



@app.post("/user_responses/")
def create_user_response(response: UserResponseSchema, db: Session = Depends(get_db)):
    stmt = add_user_response(response)
    db.execute(stmt)
    db.commit()
    return response


@app.get("/final_recommendation/{user_id}")
def get_recommendations(user_id: str):
    selected_books = np.array(list(presented_books)[-5:])
    selected_embeddings = book_embeddings[selected_books]
    weights = np.arange(1, len(selected_books) + 1)  # ê°€ì¤‘ì¹˜ ì¶”ê°€  ######### ë‹¤ì‹œ ë³¼ í•„ìš” ìˆìŒ
    preference_center = np.average(selected_embeddings, axis=0, weights=weights).reshape(1, -1)


    # ì¤‘ì‹¬ê³¼ ìœ ì‚¬í•œ ì±… ì¶”ì²œ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ì¤€)
    similarities = cosine_similarity(preference_center, book_embeddings).flatten()
    final_recommendations = weighted_sampling(similarities, num_samples=10, temperature=0.2)

    return final_recommendations

def first_setting_of_logic(user_id, num_clusters, embedding_save_path, db):
    global round_num, alpha, beta_values, presented_books, book_embeddings, ids, book_data, cluster_to_books
    # embedding_save_path = "notebook/notebook/data/book_embeddings.npz" 
    embedding_save_path = "embedding/book_embeddings.npz"  # ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ

    ids, book_embeddings = load_embeddings(embedding_save_path)

    book_data = get_sentence_from_db(db)

    books = [f"Book {i}" for i in range(len(ids))]  # booksëŠ” idsì˜ ê¸¸ì´ì— ë”°ë¼ ìƒì„±
    assert len(books) == len(ids), "Books length mismatch with IDs! "
    num_books = len(book_embeddings)

    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    clusters = kmeans.fit_predict(book_embeddings)

    # ê° í´ëŸ¬ìŠ¤í„°ì˜ ì±… ì¸ë±ìŠ¤ ì €ì¥
    cluster_to_books = {i: [] for i in range(num_clusters)}
    for idx, cluster_id in enumerate(clusters):
        cluster_to_books[cluster_id].append(idx)

    alpha = np.ones(num_books)
    beta_values = np.ones(num_books)

    return ids, book_embeddings, book_data, user_id, cluster_to_books


def suggest_books(book_embeddings, cluster_to_books, noise_factor, book_choice=None):
    global round_num
    if round_num < 30:  # ì´ˆë°˜ 10 ë¼ìš´ë“œ ë™ì•ˆ ì§€ìˆ˜ì  ê°ì†Œ
        exploration_prob = initial_prob * (decay_factor ** round_num)
    else:  # ì´í›„ì—ëŠ” UCB ê¸°ë°˜ ì¡°ì •
        total_selections = len(presented_books)
        exploration_prob = uncertainty_factor / (uncertainty_factor + total_selections)

    book_a, book_b = select_books(book_embeddings, cluster_to_books, alpha, 
                                    beta_values, presented_books, exploration_prob, 
                                    noise_factor, book_choice)
    return book_a, book_b


@app.get("/books/{isbn}", response_model=BookSchema)
def read_book(isbn: str, db: Session = Depends(get_db)):
    book = get_book_by_isbn(db, isbn)
    if book is None:
        raise HTTPException(
            status_code=404,
            detail=f"Book with ISBN {isbn} not found."
        )
    return book

@app.get("/question_number/{user_id}", response_model=BookSchema)
def get_question_number(user_id: str, db: Session = Depends(get_db)):
    question_number = get_question_number_by_user_id(db, user_id)
    if question_number is None:
        raise HTTPException(
            status_code=404,
            detail=f"Book with ISBN {user_id} not found."
        )
    return question_number



def choice_arrange(user_id, question_number, book_a, book_b):
    cursor = get_cursor(host, port, user, password, database_name)
    choice_bool = get_choice_bool(cursor,user_id, question_number)

    if choice_bool[0]:
        choice = 'a'
    elif choice_bool[1]:
        choice = 'b'
    else:
        choice = None

    # ë°ì´í„° ì—…ë°ì´íŠ¸
    if choice:
        book_choice = update_data(choice, book_a, book_b, alpha, beta_values)
        return book_choice
    else:
        update_data(choice, book_a, book_b, alpha, beta_values)
        return None


def get_message_by_id(ids, book_id, book_data):
    """
    idsì™€ book_dataë¥¼ ì´ìš©í•´ íŠ¹ì • book_idì˜ ë©”ì‹œì§€ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    idx = np.where(ids == book_id)[0][0]  # book_idì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
    return book_data[idx]["sentence"]


def get_isbn_by_id(ids, book_id, book_data):
    """
    idsì™€ book_dataë¥¼ ì´ìš©í•´ íŠ¹ì • book_idì˜ ë©”ì‹œì§€ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    idx = np.where(ids == book_id)[0][0]  # book_idì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
    return book_data[idx]["isbn"]


def get_cursor(host, port, user, password, database_name):
    conn = psycopg2.connect(
            host=host,
            port=port,
            user=user,
            password=password,
            dbname=database_name
        )
    conn.autocommit = True
    cursor = conn.cursor()
    
    return cursor

# ì•ŒíŒŒ, ë² íƒ€ ì—…ë°ì´íŠ¸ ì—¬ë¶€ í™•ì¸ì„ ìœ„í•œ í•¨ìˆ˜
def print_nonone(arr, name):
    """ë°°ì—´ì—ì„œ 1ì´ ì•„ë‹Œ ê°’ì˜ ì¸ë±ìŠ¤ì™€ ê°’ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
    nonone_indices = np.where(arr != 1)[0]  # 1ì´ ì•„ë‹Œ ê°’ë“¤ì˜ ì¸ë±ìŠ¤
    if len(nonone_indices) == 0:
        print(f"{name} ë°°ì—´ì— 1ì´ ì•„ë‹Œ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"{name} ë°°ì—´ì˜ 1ì´ ì•„ë‹Œ ê°’ë“¤:")
        for idx in nonone_indices:
            print(f"Index: {idx}, Value: {arr[idx]}")




@app.get("/recommendation/{user_id}")
def get_book_suggestions(user_id: str, db: Session = Depends(get_db)):
    global cluster_to_books, book_embeddings, book_data, ids, book_a, book_b

    question_number = get_question_number_by_user_id(db, user_id)
    print('question_number:!!!!!!!!!!!!!!!!!!!!!!!!!!!!', question_number)

     # ì„ íƒëœ ì±…ì„ ì €ì¥í•  ë³€ìˆ˜
    book_a_isbn = None
    book_b_isbn = None
    message_a = None
    message_b = None

    # ğŸ”¹ cluster_to_booksê°€ Noneì´ë©´ ì´ˆê¸°í™”
    if cluster_to_books is None or book_embeddings is None or book_data is None:
        print("Initializing cluster_to_books and embeddings...")
        ids, book_embeddings, book_data, user_id, cluster_to_books = first_setting_of_logic(
            user_id, num_clusters, embedding_save_path, db
        )

    if question_number == 0:
        book_a, book_b = suggest_books(book_embeddings, cluster_to_books, noise_factor)
        print("This is 'if' :", book_a, book_b)
    else:
        print("This is 'else' - first :", book_a, book_b)
        book_choice_updated = choice_arrange(user_id, question_number, book_a, book_b)
        print("book_choice_updated : ", book_choice_updated)
        book_a, book_b = suggest_books(book_embeddings, cluster_to_books, noise_factor, book_choice_updated)
        print("This is 'else' -second :", book_a, book_b)

    # book_a, book_bê°€ Noneì´ ì•„ë‹ ë•Œë§Œ ì‹¤í–‰
    if book_a is not None and book_b is not None:
        question_number += 1
        book_a_isbn = get_isbn_by_id(ids, ids[book_a], book_data)
        book_b_isbn = get_isbn_by_id(ids, ids[book_b], book_data)

        message_a = get_message_by_id(ids, ids[book_a], book_data)
        message_b = get_message_by_id(ids, ids[book_b], book_data)


    print('\n')
    print(f"Round {question_number}: Choose between:")
    print(f"a: {message_a}")
    print(f"b: {message_b}")
    print_nonone(alpha, "alpha")
    print_nonone(beta_values, "beta")
    print('\n')
    # print_nonone(beta_values, "beta")
    # for el in alpha:
    #     print(el)

    # ISBN + ë¬¸ì¥ì„ í•¨ê»˜ ë°˜í™˜
    return JSONResponse(
        content={
            "bookA": {"question_num": question_number, "sentence_id": str(book_a), "isbn": str(book_a_isbn), "sentence": message_a},
            "bookB": {"question_num": question_number, "sentence_id": str(book_b), "isbn": str(book_b_isbn), "sentence": message_b}
        },
        headers={"Content-Type": "application/json; charset=utf-8"}
    )