{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0) ë°ì´í„° í™•ì¸, ì „ì²˜ë¦¬ - í•„ìš”ì—†ìŒ/ì™„ë£Œ íŒŒì¼ ë“œë¼ì´ë¸Œì— ì—…ë¡œë“œ ì™„ë£Œ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                0\n",
      "description          0\n",
      "key_sentences        0\n",
      "author               0\n",
      "publisher            0\n",
      "isbn13              13\n",
      "img_url              0\n",
      "publication_date    14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# None ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "file_path = \"../data/scraping/all_book_data_ver3.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# JSON ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸ í›„ ë³€í™˜\n",
    "if isinstance(data, list):\n",
    "    df = pd.DataFrame(data)\n",
    "elif isinstance(data, dict):  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì´ë©´ ë³€í™˜ (ì˜ˆ: {key: list})\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# None ê°’ í™•ì¸\n",
    "none_count = df.isna().sum()\n",
    "\n",
    "print(none_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¤‘ë³µ null 13ê°œ + pulication_date 1ê°œ => ì´ 14ê°œ null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìˆ˜ì • ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼: ../data/scraping/all_book_data_ver3_cleaned.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# JSON íŒŒì¼ ë¡œë“œ\n",
    "file_path = \"../data/scraping/all_book_data_ver3.json\"  # íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "if isinstance(data, list):\n",
    "    df = pd.DataFrame(data)\n",
    "elif isinstance(data, dict):  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì´ë©´ ë³€í™˜\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# ğŸ“Œ 'ISBN' ì ‘ë‘ì‚¬ ì œê±°\n",
    "df[\"isbn13\"] = df[\"isbn13\"].astype(str).str.replace(r'^ISBN', '', regex=True)\n",
    "\n",
    "# ğŸ“Œ ì´ë¯¸ì§€ URL ë³€í™˜ (JSON ë°ì´í„°ê°€ ë¡œë“œëœ í›„ ì§ì ‘ ìˆ˜ì •)\n",
    "df[\"img_url\"] = df[\"img_url\"].astype(str).apply(lambda x: x.replace(\"\\\\/\", \"/\"))\n",
    "\n",
    "# ğŸ“Œ `isbn13` ê°’ì´ ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš° ì‚­ì œ\n",
    "df = df[df[\"isbn13\"].str.isdigit()]  # ìˆ«ìë¡œë§Œ ì´ë£¨ì–´ì§„ isbn13 ê°’ë§Œ ìœ ì§€\n",
    "\n",
    "# ğŸ“Œ 'isbn13' ë˜ëŠ” 'publication_date' ê°’ì´ Noneì¸ í–‰ ì‚­ì œ\n",
    "df.dropna(subset=['isbn13', 'publication_date'], inplace=True)\n",
    "\n",
    "# ğŸ“Œ ëª¨ë“  ì»¬ëŸ¼ì—ì„œ í•˜ë‚˜ë¼ë„ None ê°’ì´ ìˆëŠ” í–‰ ì‚­ì œ\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ğŸ“Œ ìˆ˜ì •ëœ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥\n",
    "output_path = \"../data/scraping/all_book_data_ver3_cleaned.json\"\n",
    "df.to_json(output_path, orient=\"records\", force_ascii=False, indent=4)\n",
    "\n",
    "print(f\"âœ… ìˆ˜ì • ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•µì‹¬ ë¬¸ì¥ í•„í„°ë§ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨:  ../data/scraping/all_book_data_ver3_filtered.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# ğŸ“Œ JSON íŒŒì¼ ê²½ë¡œ\n",
    "json_file_path = \"../data/scraping/all_book_data_ver3_cleaned.json\"\n",
    "output_json_path = \"../data/scraping/all_book_data_ver3_filtered.json\"\n",
    "\n",
    "# JSON íŒŒì¼ ë¡œë“œ\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    book_data = json.load(f)\n",
    "\n",
    "\n",
    "filtered_books = []\n",
    "for book in book_data:\n",
    "    if \"key_sentences\" in book and \"isbn13\" in book:\n",
    "        if isinstance(book[\"key_sentences\"], str):\n",
    "            # 1ï¸âƒ£ 'ì¤‘ì—ì„œ' ì´í›„ì˜ ë‚´ìš© ì œê±°\n",
    "            book[\"key_sentences\"] = re.split(r'ì¤‘ì—ì„œ', book[\"key_sentences\"], maxsplit=1)[0].strip() + 'ì¤‘ì—ì„œ' if 'ì¤‘ì—ì„œ' in book[\"key_sentences\"] else book[\"key_sentences\"]\n",
    "            # 2ï¸âƒ£ '--- p.ìˆ«ì' ë“±ì˜ êµ¬ë¶„ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬\n",
    "            book[\"key_sentences\"] = re.split(r'---', book[\"key_sentences\"], maxsplit=1)[0].strip()\n",
    "\n",
    "            filtered_books.append({\n",
    "                \"isbn\" : book[\"isbn13\"],\n",
    "                \"key_sentences\": book[\"key_sentences\"]\n",
    "            })\n",
    "\n",
    "            \n",
    "# Json íŒŒì¼ ì €ì¥\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_books, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"í•µì‹¬ ë¬¸ì¥ í•„í„°ë§ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨: \", output_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) ë°ì´í„°ë² ì´ìŠ¤ê°€ í…Œì´ë¸”ì´ ìƒì„±ë˜ê³  json íŒŒì¼ì´ë‘ DBë‘ ì—°ê²°\n",
    "- êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ all_book_data_ver3_cleaned.jsoníŒŒì¼ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.history import HistoryManager\n",
    "\n",
    "# history_manager = HistoryManager()\n",
    "# history_manager.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database settings successfully!\n"
     ]
    }
   ],
   "source": [
    "# Python ê²½ë¡œ ì¶”ê°€\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "\n",
    "from app.database.connection import DatabaseSettings, create_connection\n",
    "from app.services.data_ingestion_service import create_tables\n",
    "from app.services.data_insert_DB import insert_books\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •\n",
    "db_settings = DatabaseSettings()\n",
    "conn = create_connection(db_settings)\n",
    "\n",
    "if conn:\n",
    "    # í…Œì´ë¸” ìƒì„±\n",
    "    create_tables(conn)\n",
    "    print('success')\n",
    "\n",
    "    # JSON íŒŒì¼ ê²½ë¡œ\n",
    "    json_file_path = \"../data/scraping/all_book_data_ver3_cleaned.json\"\n",
    "\n",
    "    # JSON ë°ì´í„°ë¥¼ í…Œì´ë¸”ì— ì‚½ì…\n",
    "    insert_books(conn, json_file_path)\n",
    "\n",
    "    # ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n",
    "    def test_connection(conn):\n",
    "        \"\"\"í…Œì´ë¸” ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT * FROM books;\")\n",
    "            rows = cursor.fetchall()\n",
    "            if rows:\n",
    "                for row in rows:\n",
    "                    print(row)\n",
    "            else:\n",
    "                print(\"No data found in 'books' table.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error during connection test:\", e)\n",
    "        finally:\n",
    "            cursor.close()\n",
    "\n",
    "    test_connection(conn)\n",
    "\n",
    "    # ì—°ê²° ì¢…ë£Œ\n",
    "    conn.close()\n",
    "    print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jin0/Project/Book-reccomendation/test\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())  \u001b[38;5;66;03m# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ì¶œë ¥\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[43mjson_file\u001b[49m))  \u001b[38;5;66;03m# íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json_file' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ì¶œë ¥\n",
    "print(os.path.exists(json_file))  # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jin0/Project/Book-reccomendation/test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # í˜„ì¬ ë””ë ‰í† ë¦¬ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„±ë¬¸ìì™€ í•´ì‹œíƒœê·¸ ë°ì´í„° ì ì¬\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸ ë° í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "current_dir = os.getcwd()\n",
    "project_dir = os.path.abspath(os.path.join(current_dir, \"../\"))  # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ìƒìœ„ ë‘ ë‹¨ê³„ ê²½ë¡œë¥¼ ì¶”ì \n",
    "sys.path.append(project_dir)\n",
    "\n",
    "# ë°ì´í„° ì‚½ì… í•¨ìˆ˜ import\n",
    "from app.services.data_insert_DB import insert_hashtag_message_data\n",
    "from app.database.connection import DatabaseSettings, create_connection\n",
    "\n",
    "def main():\n",
    "    settings = DatabaseSettings()  # DB ì„¤ì • ê°ì²´ ìƒì„±\n",
    "    conn = create_connection(settings)  # DB ì—°ê²°\n",
    "    \n",
    "    if conn:\n",
    "        try:\n",
    "            with conn.cursor() as cursor:\n",
    "                json_file = \"../data/scraping/all_book_data_ver3_cleaned.json\"  # íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ìˆ˜ì •\n",
    "                insert_hashtag_message_data(cursor, json_file)\n",
    "            conn.commit()\n",
    "            print(\"âœ… ë°ì´í„° ì‚½ì… ì™„ë£Œ!\")\n",
    "        except Exception as e:\n",
    "            conn.rollback()\n",
    "            print(f\"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        finally:\n",
    "            conn.close()\n",
    "            print(\"ğŸ“Œ Database connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.services.data_insert_DB import insert_hashtag_message_data\n",
    "from app.database.connection import DatabaseSettings, create_connection\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_recommend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
